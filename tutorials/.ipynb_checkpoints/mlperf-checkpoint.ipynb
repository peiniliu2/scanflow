{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPERF INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts from Lenovo paper\n",
    "\n",
    "- Inference is more difficult than training because latency, throughput, and efficiency need to be balanced. Furthermore, a more complex infrastructure and evaluation criteria is needed.\n",
    "- Balance also accuracy by pruning networks or lowering numerical precision (quantization).\n",
    "- Multiple scenarios to consider: Classification, detection, NLP.\n",
    "- Review of past benchmark initiatives: DeepBench, DAWNBench. MLPerf differs from others, due to number of tasks, more metrics, wider support by companies.\n",
    "- MLPerf is only focused on DL tasks wheres other steps beyond training and inference are relegated such as data handling, preparation, monitoring, continous learning.\n",
    "- The LoadGen module sends requests to the Model. \n",
    "- LoadGen supports 4 tupes of queries: Single-stream, Multistream, Server, Offline.\n",
    "- In offline (batch) scenario GPU performs better than CPU.\n",
    "- A comparison table is shown that depicts the throughput of different accelerators. This is the benchmark.\n",
    "- Lenovo DCG is preparing to submit the Inferenve v0.7 benchmark.\n",
    "- The benchmarking feature (not the competition) is useful for Lenovo to verify performance on its server portfolio.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts about MLPerf for Scanflow\n",
    "\n",
    "- It is interesting the types of inference applied to a model: single-stream, multi-stream, server, offline.\n",
    "- It is helpful to check the variaty of data structure used in the inference, such as, images, texts, tabular.\n",
    "- Adapt the log values into the scanflow Tracking (queries, queries per second, etc.).\n",
    "\n",
    "# Thoughts about Scanflow for MLPerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/guess/Desktop/scanflow/examples/mlperf/workflow/models'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"MODEL_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import click\n",
    "\n",
    "\n",
    "# @click.command(help=\"usage: python tf|onnxruntime|pytorch|tflite \\\n",
    "#                [resnet50|mobilenet|ssd-mobilenet|ssd-resnet34] [cpu|gpu]\")\n",
    "# @click.option(\"--backend\", help=\"tf|onnxruntime|pytorch|tflite\",\n",
    "#               type=click.Choice(['tf', 'onnxruntime', 'pytorch', \n",
    "#                                 'tflite']), default=\"tf\")\n",
    "# @click.option(\"--model\", help=\"resnet50|mobilenet|ssd-mobilenet|ssd-resnet34\",\n",
    "#               type=click.Choice(['resnet50', 'mobilenet', 'ssd-mobilenet', \n",
    "#                                 'ssd-resnet34']), default=\"resnet50\")\n",
    "# @click.option(\"--device\", help=\"cpu|gpu\",\n",
    "#               type=click.Choice(['cpu', 'gpu']), default=\"cpu\")\n",
    "def get_params(backend, model, device):\n",
    "    if device == 'cpu':\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    \n",
    "    name = f\"{model}-{backend}\"\n",
    "    extra_args=\"\"\n",
    "    MODEL_DIR = os.environ[\"MODEL_DIR\"]\n",
    "    # Tensorflow\n",
    "    if name == \"resnet50-tf\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"resnet50_v1.pb\")\n",
    "        profile = \"resnet50-tf\"\n",
    "    elif name == \"mobilenet-tf\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"mobilenet_v1_1.0_224_frozen.pb\")\n",
    "        profile = \"mobilenet-tf\"\n",
    "    elif name == \"ssd-mobilenet-tf\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"ssd_mobilenet_v1_coco_2018_01_28.pb\")\n",
    "        profile = \"ssd-mobilenet-tf\"        \n",
    "    elif name == \"ssd-resnet34-tf\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"resnet34_tf.22.1.pb\")\n",
    "        profile = \"ssd-resnet34-tf\"\n",
    "\n",
    "    # onnxruntime\n",
    "    if name == \"resnet50-onnxruntime\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"resnet50_v1.onnx\")\n",
    "        profile = \"resnet50-onnxruntime\"\n",
    "    elif name == \"mobilenet-onnxruntime\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"mobilenet_v1_1.0_224.onnx\")\n",
    "        profile = \"mobilenet-onnxruntime\"\n",
    "    elif name == \"ssd-mobilenet-onnxruntime\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"ssd_mobilenet_v1_coco_2018_01_28.pb\")\n",
    "        profile = \"ssd-mobilenet-onnxruntime\"        \n",
    "    elif name == \"ssd-resnet34-onnxruntime\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"resnet34-ssd1200.onnx\")\n",
    "        profile = \"ssd-resnet34-onnxruntime\"\n",
    "    elif name == \"ssd-resnet34-tf-onnxruntime\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"ssd_resnet34_mAP_20.2.onnx\")\n",
    "        profile = \"ssd-resnet34-onnxruntime-tf\"\n",
    "        \n",
    "    # pytorch\n",
    "    \n",
    "    if name == \"resnet50-pytorch\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"resnet50_v1.onnx\")\n",
    "        profile = \"resnet50-pytorch\"\n",
    "    elif name == \"mobilenet-pytorch\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"mobilenet_v1_1.0_224.onnx\")\n",
    "        profile = \"mobilenet-pytorch\"\n",
    "    elif name == \"ssd-mobilenet-pytorch\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"ssd_mobilenet_v1_coco_2018_01_28.pb\")\n",
    "        profile = \"ssd-mobilenet-pytorch\"        \n",
    "    elif name == \"ssd-resnet34-pytorch\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"resnet34_tf.22.1.pb\")\n",
    "        profile = \"ssd-resnet34-pytorch\"\n",
    "        \n",
    "    # tflite\n",
    "    \n",
    "    if name == \"resnet50-tflite\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"resnet50_v1.tflite\")\n",
    "        profile = \"resnet50-tf\"\n",
    "        extra_args=f\"{extra_args} --backend tflite\"\n",
    "        \n",
    "    elif name == \"mobilenet-tflite\":\n",
    "        model_path = os.path.join(MODEL_DIR, \"mobilenet_v1_1.0_224.tflite\")\n",
    "        profile = \"mobilenet-tf\"\n",
    "        extra_args=f\"{extra_args} --backend tflite\"\n",
    "#     else:\n",
    "#         print(\"Incorrect backend\")\n",
    "#         sys.exit(1)\n",
    "        \n",
    "    name = f\"{backend}-{device}/{model}\"\n",
    "    os.environ[\"EXTRA_OPS\"] = f\"{extra_args} {os.environ['EXTRA_OPS']}\"\n",
    "    \n",
    "    return name, model_path, profile\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     if 'DATA_DIR' in os.environ:\n",
    "#         DATA_DIR = os.environ['DATA_DIR']\n",
    "#     else:\n",
    "#         print(\"DATA_DIR not set\")\n",
    "#         sys.exit(1)\n",
    "        \n",
    "#     if 'MODEL_DIR' in os.environ:\n",
    "#         MODEL_DIR = os.environ['MODEL_DIR']\n",
    "#     else:\n",
    "#         print(\"MODEL_DIR not set\")\n",
    "#         sys.exit(1)\n",
    "        \n",
    "\n",
    "#     get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/guess/Desktop/scanflow/examples/mlperf/workflow/output/tf-cpu/resnet50'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/home/guess/Desktop/scanflow/examples/mlperf/workflow'\n",
    "os.environ['MODEL_DIR'] = os.path.join(root, 'models')\n",
    "os.environ['DATA_DIR'] = os.path.join(root, \"fake_imagenet\")\n",
    "os.environ['EXTRA_OPS'] =\"--samples-per-query 20 --time 10 --max-latency 0.2 --accuracy\"\n",
    "\n",
    "backend = \"tf\"\n",
    "model = \"resnet50\"\n",
    "device = \"cpu\"\n",
    "\n",
    "name, model_path, profile = get_params(backend, model, device)\n",
    "\n",
    "OUTPUT_DIR = os.path.join(root, 'output', name)\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctn_root = '/mlperf'\n",
    "ctn_data = os.path.basename(os.environ['DATA_DIR'])\n",
    "ctn_data = os.path.join(ctn_root, ctn_data)\n",
    "ctn_output = os.path.join(ctn_root, 'output')\n",
    "ctn_model = os.path.basename(os.environ['MODEL_DIR'])\n",
    "ctn_model = os.path.join(ctn_root, ctn_model, 'resnet50_v1.pb')\n",
    "\n",
    "# volumes = {os.environ['DATA_DIR']: {'bind': ctn_data, 'mode':'rw'},\n",
    "#           os.environ['MODEL_DIR']: {'bind': ctn_model, 'mode':'rw'},\n",
    "#           '/proc': {'bind': '/host_proc', 'mode':'rw'},\n",
    "#           OUTPUT_DIR: {'bind': ctn_output, 'mode':'rw'},\n",
    "#           app_dir: {'bind': ctn_root, 'mode':'rw'}}\n",
    "\n",
    "volumes = {'/proc': {'bind': '/host_proc', 'mode':'rw'},\n",
    "          root: {'bind': ctn_root, 'mode':'rw'}}    \n",
    "    \n",
    "environment = {'opts': f\"--mlperf_conf ./mlperf.conf --profile {profile} --model {ctn_model} \\\n",
    "   --dataset-path {ctn_data} --output {ctn_output} {os.environ['EXTRA_OPS']}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlperf_conf': './mlperf.conf',\n",
       " 'profile': 'resnet50-tf',\n",
       " 'model': '/mlperf/models/resnet50_v1.pb',\n",
       " 'dataset-path': '/mlperf/fake_imagenet',\n",
       " 'output': '/mlperf/output',\n",
       " 'time': 10,\n",
       " 'max-latency': 0.2,\n",
       " 'accuracy': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_params = {'mlperf_conf': './mlperf.conf', 'profile': profile,\n",
    "               'model': ctn_model, 'dataset-path': ctn_data,\n",
    "               'output': ctn_output, 'time': 10, 'max-latency': 0.2,\n",
    "               'accuracy': ''}\n",
    "base_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 4.62 ms, total: 20.6 ms\n",
      "Wall time: 22.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Setup = (\n",
       "    Workflows: ['workflow1']\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from scanflow.setup import Setup, Executor, Tracker, Workflow\n",
    "from scanflow.deploy import Deploy\n",
    "\n",
    "# App folder\n",
    "app_dir = '/home/guess/Desktop/scanflow/examples/mlperf/'\n",
    "\n",
    "executors = [Executor(name='mlperf-1', \n",
    "                       file='python/mlperf_main.py',\n",
    "#                        file='python/main.py',\n",
    "                       parameters=dict({'samples-per-query': 20},\n",
    "                                       **base_params),\n",
    "#                        dockerfile='Dockerfile2.cpu',\n",
    "                       env='mlperf-infer-imgclassify-cpu:mlflow'),\n",
    "              \n",
    "             Executor(name='mlperf-2', \n",
    "                       file='python/mlperf_main.py',\n",
    "#                        file='python/main.py',\n",
    "                       parameters=dict({'samples-per-query': 1000},\n",
    "                                       **base_params),\n",
    "#                        dockerfile='Dockerfile2.cpu',\n",
    "                       env='mlperf-infer-imgclassify-cpu:mlflow')\n",
    "            \n",
    "]\n",
    "\n",
    "workflow1 = Workflow(name='workflow1', \n",
    "                     executors=executors,\n",
    "                     tracker=Tracker(port=8001))\n",
    "\n",
    "\n",
    "workflower = Setup(app_dir, workflows=[workflow1],\n",
    "                             verbose=False)\n",
    "\n",
    "# Build the nodes\n",
    "workflower.build_workflows()\n",
    "workflower\n",
    "# Start containers and run workflows\n",
    "# deployer = Deploy(app_dir, workflower, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]12-Oct-20 11:17:31 -  INFO - [++] Starting workflow: [workflow1].\n",
      "12-Oct-20 11:17:31 -  WARNING - [+] Network: [network_workflow1] is already running.\n",
      "12-Oct-20 11:17:31 -  INFO - [+] Starting env: [workflow1:mlperf-1].\n",
      "12-Oct-20 11:17:31 -  INFO - [+] Environment: [mlperf-1] has not been started in local. Starting a new one.\n",
      "12-Oct-20 11:17:31 -  INFO - [+] Starting env: [workflow1:mlperf-2].\n",
      "12-Oct-20 11:17:31 -  INFO - [+] Environment: [mlperf-2] has not been started in local. Starting a new one.\n",
      "12-Oct-20 11:17:32 -  INFO - [+] Starting image: [tracker-workflow1.\n",
      "12-Oct-20 11:17:32 -  INFO - [+] Environment: [tracker-workflow1] has not been started in local. Starting a new one.\n",
      "12-Oct-20 11:17:32 -  INFO - [+] Workflow: [workflow1] was started successfully.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# Start containers\n",
    "\n",
    "deployer = Deploy(app_dir, workflower, verbose=True)\n",
    "\n",
    "deployer.start_workflows(volumes=volumes, environment=environment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployer.stop_workflows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 8.851582765579224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deployer.run_workflows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workflower.draw_workflow('My inferences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "inferences = [\"inference1\", \"inference2\", \"inference3\"]\n",
    "\n",
    "for inf in inferences:\n",
    "    for i in range(5):\n",
    "        with mlflow.start_run(run_name=inf) as mlrun:\n",
    "\n",
    "            queries = int(np.random.rand()*10)\n",
    "            eta = np.random.rand()\n",
    "            acc = np.random.rand()\n",
    "            mlflow.log_param(key='backend', value=backend)\n",
    "            mlflow.log_param(key='model', value=model)\n",
    "            mlflow.log_param(key='device', value=device)\n",
    "\n",
    "            mlflow.log_metric(key='queries', value=queries)\n",
    "            mlflow.log_metric(key='time', value=eta)\n",
    "            mlflow.log_metric(key='queries_per_second', value=round(queries/eta, 2))\n",
    "            mlflow.log_metric(key='accuracy', value=acc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.time</th>\n",
       "      <th>metrics.queries_per_second</th>\n",
       "      <th>metrics.queries</th>\n",
       "      <th>metrics.accuracy</th>\n",
       "      <th>metrics.qps</th>\n",
       "      <th>params.backend</th>\n",
       "      <th>params.device</th>\n",
       "      <th>params.model</th>\n",
       "      <th>params.arguments</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3de3c4bab35c4e13990a1d8047e9030f</td>\n",
       "      <td>0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///home/guess/Desktop/scanflow/tutorials/...</td>\n",
       "      <td>2020-09-29 10:00:39.943000+00:00</td>\n",
       "      <td>2020-09-29 10:00:39.985000+00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>cpu</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>inference</td>\n",
       "      <td>/home/guess/anaconda3/envs/venv2/lib/python3.7...</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d22d45cfa59f450f8daf5c10d0790784</td>\n",
       "      <td>0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///home/guess/Desktop/scanflow/tutorials/...</td>\n",
       "      <td>2020-09-29 10:00:21.927000+00:00</td>\n",
       "      <td>2020-09-29 10:00:21.977000+00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>cpu</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>inference</td>\n",
       "      <td>/home/guess/anaconda3/envs/venv2/lib/python3.7...</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d73988640f634476af3aab18296a3309</td>\n",
       "      <td>0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///home/guess/Desktop/scanflow/tutorials/...</td>\n",
       "      <td>2020-09-29 09:51:26.839000+00:00</td>\n",
       "      <td>2020-09-29 09:51:26.878000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.23</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>cpu</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>inference</td>\n",
       "      <td>/home/guess/anaconda3/envs/venv2/lib/python3.7...</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0261193623f5402aadd6253da7c12343</td>\n",
       "      <td>0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>file:///home/guess/Desktop/scanflow/tutorials/...</td>\n",
       "      <td>2020-09-29 09:51:18.429000+00:00</td>\n",
       "      <td>2020-09-29 09:51:18.443000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>inference</td>\n",
       "      <td>/home/guess/anaconda3/envs/venv2/lib/python3.7...</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0feec34cebfa4838bc469c391b2230c6</td>\n",
       "      <td>0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///home/guess/Desktop/scanflow/tutorials/...</td>\n",
       "      <td>2020-09-29 09:43:32.181000+00:00</td>\n",
       "      <td>2020-09-29 09:43:32.205000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.23</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>cpu</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>inference</td>\n",
       "      <td>/home/guess/anaconda3/envs/venv2/lib/python3.7...</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fe62f1c148c84201ab517cf55ad0a87a</td>\n",
       "      <td>0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///home/guess/Desktop/scanflow/tutorials/...</td>\n",
       "      <td>2020-09-29 09:40:31.868000+00:00</td>\n",
       "      <td>2020-09-29 09:40:31.921000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'backend': 'pytorch', 'model': 'resnet50', 'd...</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>inference</td>\n",
       "      <td>/home/guess/anaconda3/envs/venv2/lib/python3.7...</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d2312a3e8f594b4ab55dc68ca303a9db</td>\n",
       "      <td>0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>file:///home/guess/Desktop/scanflow/tutorials/...</td>\n",
       "      <td>2020-09-29 09:39:03.263000+00:00</td>\n",
       "      <td>2020-09-29 09:39:03.276000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>inference</td>\n",
       "      <td>/home/guess/anaconda3/envs/venv2/lib/python3.7...</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status  \\\n",
       "0  3de3c4bab35c4e13990a1d8047e9030f             0  FINISHED   \n",
       "1  d22d45cfa59f450f8daf5c10d0790784             0  FINISHED   \n",
       "2  d73988640f634476af3aab18296a3309             0  FINISHED   \n",
       "3  0261193623f5402aadd6253da7c12343             0    FAILED   \n",
       "4  0feec34cebfa4838bc469c391b2230c6             0  FINISHED   \n",
       "5  fe62f1c148c84201ab517cf55ad0a87a             0  FINISHED   \n",
       "6  d2312a3e8f594b4ab55dc68ca303a9db             0    FAILED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  file:///home/guess/Desktop/scanflow/tutorials/...   \n",
       "1  file:///home/guess/Desktop/scanflow/tutorials/...   \n",
       "2  file:///home/guess/Desktop/scanflow/tutorials/...   \n",
       "3  file:///home/guess/Desktop/scanflow/tutorials/...   \n",
       "4  file:///home/guess/Desktop/scanflow/tutorials/...   \n",
       "5  file:///home/guess/Desktop/scanflow/tutorials/...   \n",
       "6  file:///home/guess/Desktop/scanflow/tutorials/...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2020-09-29 10:00:39.943000+00:00 2020-09-29 10:00:39.985000+00:00   \n",
       "1 2020-09-29 10:00:21.927000+00:00 2020-09-29 10:00:21.977000+00:00   \n",
       "2 2020-09-29 09:51:26.839000+00:00 2020-09-29 09:51:26.878000+00:00   \n",
       "3 2020-09-29 09:51:18.429000+00:00 2020-09-29 09:51:18.443000+00:00   \n",
       "4 2020-09-29 09:43:32.181000+00:00 2020-09-29 09:43:32.205000+00:00   \n",
       "5 2020-09-29 09:40:31.868000+00:00 2020-09-29 09:40:31.921000+00:00   \n",
       "6 2020-09-29 09:39:03.263000+00:00 2020-09-29 09:39:03.276000+00:00   \n",
       "\n",
       "   metrics.time  metrics.queries_per_second  metrics.queries  \\\n",
       "0           0.6                   13.330000              8.0   \n",
       "1           0.6                   13.333333              8.0   \n",
       "2           NaN                         NaN              NaN   \n",
       "3           NaN                         NaN              NaN   \n",
       "4           NaN                         NaN              NaN   \n",
       "5           NaN                         NaN              NaN   \n",
       "6           NaN                         NaN              NaN   \n",
       "\n",
       "   metrics.accuracy  metrics.qps params.backend params.device params.model  \\\n",
       "0              0.75          NaN        pytorch           cpu     resnet50   \n",
       "1              0.75          NaN        pytorch           cpu     resnet50   \n",
       "2               NaN        13.23        pytorch           cpu     resnet50   \n",
       "3               NaN          NaN           None          None         None   \n",
       "4               NaN        13.23        pytorch           cpu     resnet50   \n",
       "5               NaN          NaN           None          None         None   \n",
       "6               NaN          NaN           None          None         None   \n",
       "\n",
       "                                    params.arguments tags.mlflow.source.type  \\\n",
       "0                                               None                   LOCAL   \n",
       "1                                               None                   LOCAL   \n",
       "2                                               None                   LOCAL   \n",
       "3                                               None                   LOCAL   \n",
       "4                                               None                   LOCAL   \n",
       "5  {'backend': 'pytorch', 'model': 'resnet50', 'd...                   LOCAL   \n",
       "6                                               None                   LOCAL   \n",
       "\n",
       "  tags.mlflow.runName                            tags.mlflow.source.name  \\\n",
       "0           inference  /home/guess/anaconda3/envs/venv2/lib/python3.7...   \n",
       "1           inference  /home/guess/anaconda3/envs/venv2/lib/python3.7...   \n",
       "2           inference  /home/guess/anaconda3/envs/venv2/lib/python3.7...   \n",
       "3           inference  /home/guess/anaconda3/envs/venv2/lib/python3.7...   \n",
       "4           inference  /home/guess/anaconda3/envs/venv2/lib/python3.7...   \n",
       "5           inference  /home/guess/anaconda3/envs/venv2/lib/python3.7...   \n",
       "6           inference  /home/guess/anaconda3/envs/venv2/lib/python3.7...   \n",
       "\n",
       "  tags.mlflow.user  \n",
       "0            guess  \n",
       "1            guess  \n",
       "2            guess  \n",
       "3            guess  \n",
       "4            guess  \n",
       "5            guess  \n",
       "6            guess  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mlflow.search_runs(['0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic manipulation: guarantee the generalization\n",
    "\n",
    "> **What happen if an inference node reach a certain limit value?. For instance, qps = 2, acc=0.6** .\n",
    ">> First, maybe the workload on that node is heavy. Therefore, there should be a mechanism to control it. For instance, perform a load balancing, spreading the traffic across diferent nodes.\n",
    ">> Second, perhaps the \"B\" model in the A/B testing is behaving badly. Therefore, automatically an action should be perfom to change the inference node to previous stable version.\n",
    "\n",
    "\n",
    " ```python\n",
    " if inference_time is critical:\n",
    "     pick model A, \n",
    " elif (accuracy is critical) \n",
    "     pick model B \n",
    " else pick model  C\n",
    " ```\n",
    "> **Can we explain tracked results (metrics)?** .\n",
    ">> Yes, because we don't only track inference values but also the whole workflow (extracting, preprocessing, feature engineering, ...). Having a graph structure allows user to traverse the workflow and get a clue about \"causality\".\n",
    "\n",
    "> **Can we add a human agent to perform certain actions?** .\n",
    ">> Yes, some events could raise an alarm (critical cases), so that a human can intervene. For instance, in a batch scenario (Offline inference) a logic bug fix is needed.\n",
    "\n",
    "> **Can we use this KB (knowledge base, tracked values somehow) to perform reasoning?** .\n",
    ">> Not at this point because it requires a cognitive framework. \n",
    "\n",
    "> **Can we use this KB (knowledge base, tracked values somehow) to perform planning?** .\n",
    ">> Not yet. However, the Scanflow's structure proposal is an initiative to at least manipulate variables to do a state-transition system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning: get insights through patterns\n",
    "\n",
    "> **Can we predict request trends?**\n",
    ">> We can use a Time series node to forecast behaviours. This is useful to prevent lack of resources, for instance.\n",
    "\n",
    "> **Can we predict anomalies on input data and metrics such as accuracy, time, qps?**\n",
    ">> Yes, using a drift distribution node. It detects anomalies on bothc requests and events regarding the platform.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
