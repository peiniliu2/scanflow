{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guess/anaconda3/lib/python3.7/site-packages/h5py/_hl/base.py:19: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import (Mapping, MutableMapping, KeysView,\n",
      "Using TensorFlow backend.\n",
      "/home/guess/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:824: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  _pywrap_tensorflow.RegisterType(\"Sequence\", _collections.Sequence)\n",
      "/home/guess/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/util.py:448: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class _ObjectIdentitySet(collections.MutableSet):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import mlflow\n",
    "import click\n",
    "import sklearn\n",
    "import logging\n",
    "import tempfile\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mlflow.keras import log_model, save_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "clump_thickness        int64\n",
       "size_uniformity        int64\n",
       "shape_uniformity       int64\n",
       "marginal_adhesion      int64\n",
       "epithelial_size        int64\n",
       "bare_nucleoli        float64\n",
       "bland_chromatin        int64\n",
       "normal_nucleoli        int64\n",
       "mitoses                int64\n",
       "class                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run matched, but is not FINISHED, so skipping (run_id=19e100eaaa3d43acb087354069404936, status=FINISHED)\n",
      "Run matched, but is not FINISHED, so skipping (run_id=6d5d47e6e19c47f99dd6f7f8e1c7f0ce, status=FINISHED)\n",
      "No matching run has been found.\n",
      "2019/10/23 21:16:43 INFO mlflow.projects: === Created directory /tmp/tmpyh9kysaw for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/10/23 21:16:43 INFO mlflow.projects: === Running command 'python gathering.py' in run with ID 'cf830250b5fe4cf5980b7d7b995e0136' === \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching new run for entrypoint=gathering and parameters={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/10/23 21:16:44 INFO mlflow.projects: === Run (ID 'cf830250b5fe4cf5980b7d7b995e0136') succeeded ===\n",
      "Run matched, but is not FINISHED, so skipping (run_id=5111b0281f8943188a1cf44259fdec24, status=FINISHED)\n",
      "Run matched, but is not FINISHED, so skipping (run_id=1fdab5dce0fc4ab2af250ee58e2ca8b1, status=FINISHED)\n",
      "No matching run has been found.\n",
      "2019/10/23 21:16:44 INFO mlflow.projects: === Created directory /tmp/tmp4mjpbee_ for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/10/23 21:16:44 INFO mlflow.projects: === Running command 'python preprocessing.py' in run with ID 'ff5f4ce9902d479a95e43129f1b7a533' === \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching new run for entrypoint=preprocessing and parameters={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/10/23 21:16:45 INFO mlflow.projects: === Run (ID 'ff5f4ce9902d479a95e43129f1b7a533') succeeded ===\n",
      "Run matched, but is not FINISHED, so skipping (run_id=fdbb8a99885f4f2ba3ab1f8e6ebd05d5, status=FAILED)\n",
      "Run matched, but is not FINISHED, so skipping (run_id=51bcddd56f544a5d93d993ef443e3b9a, status=FINISHED)\n",
      "No matching run has been found.\n",
      "2019/10/23 21:16:46 INFO mlflow.projects: === Created directory /tmp/tmp94hitiii for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2019/10/23 21:16:46 INFO mlflow.projects: === Running command 'python modeling.py' in run with ID '5ae43703d30c41e99b2c4fe9bb5990a0' === \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching new run for entrypoint=modeling and parameters={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/10/23 21:16:47 INFO mlflow.projects: === Run (ID '5ae43703d30c41e99b2c4fe9bb5990a0') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import click\n",
    "import os\n",
    "import tempfile\n",
    "import six\n",
    "import mlflow\n",
    "\n",
    "from mlflow.utils import mlflow_tags\n",
    "from mlflow.entities import RunStatus\n",
    "from mlflow.utils.logging_utils import eprint\n",
    "from mlflow.tracking.fluent import _get_experiment_id\n",
    "\n",
    "\n",
    "def _already_ran(entry_point_name, parameters, git_commit, experiment_id=None):\n",
    "    \"\"\"Best-effort detection of if a run with the given entrypoint name,\n",
    "    parameters, and experiment id already ran. The run must have completed\n",
    "    successfully and have at least the parameters provided.\n",
    "    \"\"\"\n",
    "    experiment_id = experiment_id if experiment_id is not None else _get_experiment_id()\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    all_run_infos = reversed(client.list_run_infos(experiment_id))\n",
    "    for run_info in all_run_infos:\n",
    "        full_run = client.get_run(run_info.run_id)\n",
    "        tags = full_run.data.tags\n",
    "        if tags.get(mlflow_tags.MLFLOW_PROJECT_ENTRY_POINT, None) != entry_point_name:\n",
    "            continue\n",
    "        match_failed = False\n",
    "        for param_key, param_value in six.iteritems(parameters):\n",
    "            run_value = full_run.data.params.get(param_key)\n",
    "            if run_value != param_value:\n",
    "                match_failed = True\n",
    "                break\n",
    "        if match_failed:\n",
    "            continue\n",
    "\n",
    "        if run_info.status != RunStatus.FINISHED:\n",
    "            eprint((\"Run matched, but is not FINISHED, so skipping \"\n",
    "                    \"(run_id=%s, status=%s)\") % (run_info.run_id, run_info.status))\n",
    "            continue\n",
    "\n",
    "        previous_version = tags.get(mlflow_tags.MLFLOW_GIT_COMMIT, None)\n",
    "        if git_commit != previous_version:\n",
    "            eprint((\"Run matched, but has a different source version, so skipping \"\n",
    "                    \"(found=%s, expected=%s)\") % previous_version, git_commit)\n",
    "            continue\n",
    "        return client.get_run(run_info.run_id)\n",
    "    eprint(\"No matching run has been found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# TODO(aaron): This is not great because it doesn't account for:\n",
    "# - changes in code\n",
    "# - changes in dependant steps\n",
    "def _get_or_run(entrypoint, parameters, git_commit, use_cache=True):\n",
    "    existing_run = _already_ran(entrypoint, parameters, git_commit)\n",
    "    if use_cache and existing_run:\n",
    "        print(\"Found existing run for entrypoint=%s and parameters=%s\" % (entrypoint, parameters))\n",
    "        return existing_run\n",
    "    print(\"Launching new run for entrypoint=%s and parameters=%s\" % (entrypoint, parameters))\n",
    "    submitted_run = mlflow.run(\".\", entrypoint, parameters=parameters, use_conda=False)\n",
    "    return mlflow.tracking.MlflowClient().get_run(submitted_run.run_id)\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name='single_workflow') as active_run:\n",
    "#         os.environ['SPARK_CONF_DIR'] = os.path.abspath('.')\n",
    "#         source_version = active_run.info.source_version\n",
    "    git_commit = active_run.data.tags.get(mlflow_tags.MLFLOW_GIT_COMMIT)\n",
    "    gathering = _get_or_run(\"gathering\", {}, git_commit)\n",
    "#         ratings_csv_uri = os.path.join(load_raw_data_run.info.artifact_uri, \"ratings-csv-dir\")\n",
    "#     prep_model_path = os.path.join(gathering.info.artifact_uri, \"gathered_data.csv\")\n",
    "    preprocessing = _get_or_run(\"preprocessing\", {}, git_commit)\n",
    "\n",
    "#     source_model_path = os.path.join(preprocessing.info.artifact_uri, \"preprocessed_data.csv\")\n",
    "    modeling = _get_or_run(\"modeling\", {}, git_commit)\n",
    "#     modeling = _get_or_run(\"modeling\", {'preprocessed_data':source_model_path}, git_commit)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
